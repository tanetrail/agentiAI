{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_csv_agent(\n",
    "    llm,\n",
    "    \"titanic.csv\",\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    allow_dangerous_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find the number of rows in the dataframe, I can use the `len()` function or the `.shape` attribute. I'll use the `len()` function.\n",
      "Action: python_repl_ast\n",
      "Action Input: len(df)\u001b[0m\u001b[36;1m\u001b[1;3m891\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 891\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'891'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How many rows are there in dataset ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to calculate the average fare. I can use the `mean()` method on the 'Fare' column of the dataframe.\n",
      "Action: python_repl_ast\n",
      "Action Input: `df['Fare'].mean()`\u001b[0m\u001b[36;1m\u001b[1;3m32.204207968574636\u001b[0m\u001b[32;1m\u001b[1;3mI have calculated the average fare.\n",
      "Final Answer: 32.204207968574636\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'avg price', 'output': '32.204207968574636'}\n",
      "['user_msg_1 : avg price', \"agent_msg_1 : {'input': 'avg price', 'output': '32.204207968574636'}\", 'user_msg_2 : exit']\n",
      "content='helpful' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-d77b0ca1-739e-4108-9fa7-b8365f8ac452-0' usage_metadata={'input_tokens': 101, 'output_tokens': 2, 'total_tokens': 103, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "## LLM as Judge\n",
    "knowledge_base = []\n",
    "\n",
    "message_countre = 0\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter your question : \")\n",
    "    message_countre += 1\n",
    "    user_message = f\"user_msg_{message_countre} : {user_input}\"\n",
    "    knowledge_base.append(user_message)\n",
    "\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "\n",
    "    result = agent(user_input)\n",
    "    agent_message = f\"agent_msg_{message_countre} : {result}\" \n",
    "    knowledge_base.append(agent_message)\n",
    "    print(result)\n",
    "\n",
    "## do prompt refinement for better answers as judge\n",
    "llm_as_judge_prompt=f\"\"\"\n",
    "You are a judge. You will output if the conversation is helpful or not based on the conversation and user experience.\n",
    "return \"helpful\" or \"not helpful\" only no explanation needed.\n",
    "\n",
    "Conversation:\n",
    "{knowledge_base}\n",
    "\"\"\"\n",
    "\n",
    "print(knowledge_base)\n",
    "verdict = llm.invoke(llm_as_judge_prompt)\n",
    "print(verdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
